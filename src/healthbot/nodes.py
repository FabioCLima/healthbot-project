"""N√≥s do HealthBot Graph - MVP2.

Cada fun√ß√£o representa um n√≥ que processa o estado.
MVP2 adiciona intera√ß√£o com usu√°rio atrav√©s de mensagens.
"""

from typing import Any

from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI

from healthbot.settings import settings
from healthbot.state import HealthBotState

# ============================================
# FUN√á√ïES AUXILIARES
# ============================================


def extract_message_content(message: BaseMessage) -> str:
    """Extrai o conte√∫do de uma mensagem de forma segura.

    Args:
        message: Mensagem do LangChain

    Returns:
        Conte√∫do como string, garantindo compatibilidade com tipos complexos

    """
    content = message.content  # type: ignore[misc]

    # Se j√° √© string, retorna diretamente
    if isinstance(content, str):
        return content

    # Se √© lista, tenta extrair texto dos elementos
    if isinstance(content, list):  # type: ignore[misc]
        text_parts: list[str] = []
        for item in content:  # type: ignore[misc]
            if isinstance(item, str):
                text_parts.append(item)  # type: ignore[misc]
            elif isinstance(item, dict):  # type: ignore[misc]
                # Tenta extrair texto de dicion√°rios (ex: conte√∫do multimodal)
                if "text" in item:
                    text_parts.append(str(item["text"]))  # type: ignore[misc]
                else:
                    text_parts.append(str(item))  # type: ignore[misc]
            else:
                text_parts.append(str(item))  # type: ignore[misc]
        return " ".join(text_parts)  # type: ignore[misc]

    # Fallback: converte para string
    return str(content)  # type: ignore[misc]


# ============================================
# CONFIGURA√á√ÉO DAS FERRAMENTAS
# ============================================


def get_llm() -> ChatOpenAI:
    """Retorna uma inst√¢ncia do LLM OpenAI.

    Usamos gpt-4o-mini por ser mais barato e r√°pido.

    Returns:
        Inst√¢ncia configurada do ChatOpenAI

    """
    return ChatOpenAI(
        model=settings.openai_model,
        temperature=0.7,  # Criatividade moderada
    )


def get_tavily() -> TavilySearchResults:
    """Retorna a ferramenta de busca Tavily.

    Configurada para focar em fontes m√©dicas confi√°veis.

    Returns:
        Inst√¢ncia configurada do TavilySearchResults

    """
    return TavilySearchResults(
        max_results=3,  # Pega os 3 melhores resultados
        search_depth="advanced",  # Busca mais profunda
        include_answer=True,  # Inclui resposta resumida
        include_raw_content=False,  # N√£o precisa do HTML completo
    )


# ============================================
# N√ìS DE INTERA√á√ÉO COM USU√ÅRIO (MVP2)
# ============================================

def ask_topic(_: HealthBotState) -> dict[str, Any]:
    """N√≥ 1 (MVP2): Pergunta ao usu√°rio qual t√≥pico de sa√∫de quer aprender.

    Este √© o ponto de entrada do fluxo interativo.

    Args:
        state: Estado atual do grafo

    Returns:
        Dict com mensagem perguntando o t√≥pico

    """
    message = AIMessage(
        content=(
            "Ol√°! Sou o HealthBot, seu assistente de educa√ß√£o em sa√∫de. üè•\n\n"
            "Estou aqui para ajud√°-lo a entender melhor sobre condi√ß√µes m√©dicas "
            "e cuidados com a sa√∫de.\n\n"
            "Sobre qual tema de sa√∫de voc√™ gostaria de aprender hoje?\n"
            "(Exemplos: diabetes, hipertens√£o, asma, ansiedade)"
        )
    )

    print("ü§ñ HealthBot: Perguntando t√≥pico ao usu√°rio...")

    return {"messages": [message]}


def receive_topic(state: HealthBotState) -> dict[str, Any]:
    """N√≥ 2 (MVP2): Recebe e processa o t√≥pico informado pelo usu√°rio.

    Extrai o t√≥pico da √∫ltima mensagem humana no hist√≥rico.

    Args:
        state: Estado atual (deve ter pelo menos 1 HumanMessage)

    Returns:
        Dict com o t√≥pico extra√≠do

    """
    # Pega a √∫ltima mensagem (deve ser do usu√°rio)
    last_message = state["messages"][-1]

    if isinstance(last_message, HumanMessage):
        # Extrai o conte√∫do da mensagem de forma segura
        topic = extract_message_content(last_message).strip()

        print(f"‚úÖ T√≥pico recebido: {topic}")

        confirmation = AIMessage(
            content=f"Entendi! Vou buscar informa√ß√µes confi√°veis sobre **{topic}**. "
            f"Aguarde um momento... üîç"
        )

        return {
            "topic": topic,
            "messages": [confirmation],
        }

    # Fallback (n√£o deveria chegar aqui)
    print("‚ö†Ô∏è  Aviso: Mensagem n√£o √© do tipo HumanMessage")
    return {"topic": "sa√∫de geral"}


# ============================================
# N√ìS DE PROCESSAMENTO (mantidos do MVP1)
# ============================================

def search_tavily(state: HealthBotState) -> dict[str, Any]:
    """N√≥ 3: Busca informa√ß√µes sobre o t√≥pico no Tavily.

    Args:
        state: Estado atual (precisa ter 'topic')

    Returns:
        Dict com os resultados da busca

    """
    topic = state["topic"]

    # Valida√ß√£o: se n√£o tem t√≥pico, retorna erro
    if not topic:
        print("‚ùå Erro: Nenhum t√≥pico fornecido")
        return {"results": "Erro: Nenhum t√≥pico fornecido."}

    print(f"üîç Buscando informa√ß√µes sobre: {topic}")

    # Cria query otimizada para fontes m√©dicas
    query = f"{topic} informa√ß√µes m√©dicas confi√°veis"

    # Busca no Tavily
    tavily = get_tavily()
    results = tavily.invoke({"query": query})  # type: ignore[misc]

    # Formata os resultados
    formatted_results = ""
    for i, result in enumerate(results, 1):
        formatted_results += f"\n--- Fonte {i} ---\n"
        formatted_results += f"URL: {result.get('url', 'N/A')}\n"
        formatted_results += f"Conte√∫do: {result.get('content', 'N/A')}\n"

    print(f"‚úÖ Encontradas {len(results)} fontes")

    return {"results": formatted_results}


def summarize(state: HealthBotState) -> dict[str, Any]:
    """N√≥ 4: Resume os resultados em linguagem acess√≠vel.

    Args:
        state: Estado atual (precisa ter 'topic' e 'results')

    Returns:
        Dict com o resumo gerado

    """
    topic = state["topic"]
    results = state["results"]

    # Valida√ß√£o
    if not topic or not results:
        print("‚ùå Erro: Faltam dados para resumir")
        return {"summary": "Erro: Faltam dados para resumir."}

    print(f"üìÑ Gerando resumo sobre: {topic}")

    # Prompt para o LLM
    system_msg = SystemMessage(
        content=(
            "Voc√™ √© um educador de sa√∫de especializado em comunicar "
            "informa√ß√µes m√©dicas de forma clara e acess√≠vel para pacientes.\n\n"
            "Crie um resumo educacional que:\n"
            "- Use linguagem simples (evite jarg√£o m√©dico)\n"
            "- Seja preciso e baseado nas fontes\n"
            "- Tenha entre 200-250 palavras\n"
            "- Seja informativo e pr√°tico"
        )
    )

    user_msg = HumanMessage(
        content=(
            f"Crie um resumo educacional sobre **{topic}** "
            f"baseado nestas fontes:\n\n{results}"
        )
    )

    # Gera o resumo
    llm = get_llm()
    response = llm.invoke([system_msg, user_msg])
    summary = extract_message_content(response)

    print(f"‚úÖ Resumo gerado ({len(summary)} caracteres)")

    return {"summary": summary}


def present_summary(state: HealthBotState) -> dict[str, Any]:
    """N√≥ 5: Apresenta o resumo E pergunta se est√° pronto para continuar.

    Args:
        state: Estado atual (precisa ter 'summary')

    Returns:
        Dict com mensagens contendo o resumo e a pergunta

    """
    summary = state["summary"]

    # Valida√ß√£o
    if not summary:
        print("‚ùå Erro: Nenhum resumo dispon√≠vel")
        return {"messages": [AIMessage(content="Erro: Nenhum resumo dispon√≠vel.")]}

    # Exibe no console (para debug)
    print("\n" + "=" * 70)
    print("üìã RESUMO FINAL")
    print("=" * 70)
    print()
    print(summary)
    print()
    print("=" * 70)

    print("\nüìÑ Apresentando resumo ao usu√°rio...")

    # Retorna 2 mensagens: o resumo e a pergunta
    return {
        "messages": [
            AIMessage(content=summary),
            AIMessage(
                content="\n---\n\n"
                "Quando estiver pronto para testar sua compreens√£o com um quiz, "
                "digite 'pronto' ou 'continuar'. ‚úÖ"
            ),
        ]
    }


def wait_for_ready(_: HealthBotState) -> dict[str, Any]:
    """N√≥ 6 (MVP2): Aguarda confirma√ß√£o do usu√°rio para continuar.

    Este n√≥ n√£o faz nada al√©m de validar que o usu√°rio confirmou.
    O grafo vai pausar ANTES deste n√≥ (interrupt_before).

    Args:
        state: Estado atual

    Returns:
        Dict vazio (n√£o atualiza o estado)

    """
    print("‚úÖ Usu√°rio confirmou prontid√£o")
    return {}
